---
title: DuckDB
technique: data
description: |
  We use DuckDB as a way of managing larger datasets when building sites.
  It also helps us work with other data formats, including Parquet.
---

<p>
  <a href="https://duckdb.org">DuckDB</a> is a fast in-process analytical database.
  This means it's highly optimised to deal with queries (rather than updates)
  and can work incredibly fast on very large datasets.
</p>

<p>
  As more data is rendered in a Lume site, the build can slow down significantly.
  It may be beneficial under these circumstances to use DuckDB to access data.
  This is particularly true if the data in question is very large or if it is
  used to generate very large numbers of pages.
</p>

<p>
  The <a href="https://jsr.io/@dringtech/lume-duck">lume-duck</a> module provides
  some utilities to integrate DuckDB into Lume.
</p>

<p>
  You can import the library by adding the following line to your <code>_config.ts</code> file.
</p>

<pre><code class="language-ts">import { duckDbLoader, resultTable } from "jsr:@dringtech/lume-duck";</code></pre>

<h2>
  The <code>duckDbLoader</code> dataLoader
</h2>

<p>
  The module includes a loader which converts <code>.sql</code> files in the site <code>_data/</code> directories
  into callable functions which execute the included SQL.
  These are prepared statements which can be called with parameters to customise the calls.
  Some examples are given below.
</p>

<p>
  To use the loader, add the following code to <code>_config.ts</code>.
</p>

<pre><code class="language-ts">site.loadData([".sql"], duckDbLoader());</code></pre>

<p>
  You will also need to make sure that the DuckDB C/C++ library for your system has been installed.
  You can find out how to do this on
  <a
    href="https://duckdb.org/docs/installation/"
  >the DuckDB installation documentation page</a>.
  The library also includes a provisioner, which can be used as follows:
</p>

<pre><code class="language-shell">deno run -A jsr:@dringtech/lume-duck/provisioner</code></pre>

<h2>
  The <code>resultTable</code> filter
</h2>

<p>
  The filter presents query results as a text-formatted response table.
</p>

<p>
  To use the loader, add the following code to <code>_config.ts</code>.
</p>

<pre><code class="language-ts">site.filter("resultTable", resultTable);</code></pre>

<p>
  This can be used as follows:
</p>

<pre><code class="language-ts">{{ echo }}{{ query() |> resultTable }}{{ /echo }}</code></pre>

<p>
  Examples of this are shown below.
</p>

<h2>Examples</h2>

{{ function renderExample(queryName, params, overrides) }}
  {{ set query = queryName.split('.').reduce((d, k) => d[k], page.data) }}
  <h3>Example: <code>{{ queryName }}</code></h3>
  {{ if overrides?.description }}
    {{ overrides.description }}
  {{ else }}
  <p>
    The page data item <code>{{ queryName }}</code>
    was instantiated from <code>{{ queryName |> replace(/\./, '/') }}.sql</code>.
    It contains the following query:
  </p>
  <pre><code class="language-sql">{{ query }}</code></pre>
  {{ /if }}
  <p>
    The query call
    <code>{{ queryName }}({{ overrides?.params || params |> join(", ") }})</code>,
    returns the following result:
  </p>
  <p>{{ query(...params || []) |> resultTable }}
{{ /function}}

{{ renderExample('simple', ) }}
{{ renderExample('params.incrementing', [1, 'Test'])}}
{{ renderExample('params.positional', [1, 'Test']) }}
{{ renderExample('local.csv', ) }}
{{ renderExample('local.parquet', ) }}
{{ renderExample('filtered.parquet', [2]) }}
{{ renderExample('filtered.auto', [2n], { params: ['2n'] }) }}
{{ renderExample('filtered.cast', [2]) }}
{{ renderExample('remote.describe' )}}
{{ renderExample('remote.reshape', undefined , {
  description: `<p>
    The PIVOT statement is not yet supported as a prepared statement by the DuckDB library that we're using.
    This is currently a workaround defined in <code>remote.reshape.ts</code>.
</p>`} ) }}

<h2>Hints and tips</h2>

<p>
  When loading CSV files, it pays to use the
  <a href="https://duckdb.org/docs/data/csv/overview#csv-loading">read_csv function</a>
  and explicitly set types for columns.
  The type inference tends to escalate: so integers are rendered as <code>BIGINT</code> (64-bit)
  rather than <code>INTEGER</code> (32-bit) values.
  The major issue with this is that any parameters will need to be provided as JavaScript
  <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt">BigInt</a>
  numbers (e.g. <code>12n</code> rather than <code>12</code>).
  You can, also use <a href="https://duckdb.org/docs/sql/data_types/typecasting">SQL typecasting</a> to deal with this, although it's likely to be less memory-efficient.
</p>

<p>
  The location of data files loaded via SQL is relative to the project root
  (or at least, the location of the <code>_config.ts</code> file).
  These should be kept separate from the Lume data files, to prevent
  Lume loading them into memory and defeating the object of using DuckDB in the first place!
</p>
  
</li>
</ul>
